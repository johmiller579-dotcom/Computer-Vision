This project applies Google’s Teachable Machine to develop a computer vision model that classifies images of three objects—scissors, a stapler, and an air freshener—with real-time prediction capability.## Classes Identified
List the objects your model was trained to identify:
* Class 1 (Air Freshener)
* Class 2 (Sisscors)
* Class 3 (Stapler)
1. Model Performance & Iteration

My first trained model had an accuracy of around 80–85% when identifying the three objects: air freshener, stapler, and scissors. At first, the model sometimes confused the objects when they were held at different angles or partially blocked, which caused the confidence scores to be inconsistent.

To improve performance, I added more images of each object and made sure the images were taken from multiple angles, distances, and backgrounds. I also made sure the object was clearly visible in the frame. These changes helped the model learn more variation, and the accuracy improved to around 95%. After retraining, the confidence scores were much more stable and consistently higher during testing.

2. Challenges & Observations

The stapler was the easiest object for the model to learn because it had a solid, recognizable shape and color, which made it stand out from the other two objects.

The scissors were the most challenging because their shape changes depending on whether they are open or closed, and the metal blades sometimes created reflections that confused the model.

When I tested the model with an object it had never seen before (such as a phone), the model still tried to classify it as one of the three trained objects, but with very low confidence percentages. This is important because it shows that the model doesn’t actually “know” what new objects are—it can only make a best guess using what it was trained on, even if it’s wrong.

3. Bias in AI

If I only trained a “mug” class using pictures of my one specific mug, the model would probably struggle to recognize other people’s mugs that look different in shape, color, or design. This clearly shows how bias can be created by limited training data because the model only learns a very narrow version of the object.

If all my images were taken under bright, direct lighting, the model would likely perform poorly in dimmer rooms or shadowy areas. This demonstrates how a lack of diversity in training conditions can make a model less reliable and more biased, since it is not prepared for real-world differences.

4. Model Limitations & Usefulness

Some key limitations of my model are:

It only recognizes three specific objects

It is sensitive to lighting, background, and object positioning

It cannot recognize anything outside its trained categories

It must be retrained to improve or add new objects

Being able to download the trained files such as model.json and weights.bin is valuable because it allows others to reuse, test, modify, or deploy my model in an application or website. These files contain the model’s structure and learned knowledge, which makes it possible to integrate into real-world projects or share on GitHub.

5. Real-World Applications & Ethics

Examples of real-world uses for a similar image classification model include:

Sorting items in a warehouse or office environment

Assisting with recycling and waste separation

Helping visually impaired users identify objects

One important ethical concern is privacy. If image recognition is used without permission or clear transparency, it could be used to track or monitor people. This is why developers must be careful to use AI technologies responsibly, fairly, and with consent.

(Optional) Challenges Faced / Interesting Discoveries

One interesting thing I discovered was how dramatically accuracy can improve by simply adding more diverse images. This showed me that in machine learning, data quality and variety are just as important as the model itself.
